import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import classification_report, roc_auc_score
from sklearn.ensemble import RandomForestClassifier
import tensorflow as tf
from tensorflow.keras import layers, models
import joblib
import os
import matplotlib.pyplot as plt

# 1. Load dataset
file_path = 'dataset_med.csv'   # change this if needed
data = pd.read_csv(file_path)
print("Data loaded successfully.")
print("Shape of data:", data.shape)
print(data.head())

# 2. Find or set the target column
possible_targets = ['target', 'class', 'outcome', 'label', 'cancer', 'disease', 'result']
target_column = None

for col in data.columns:
    if col.lower() in possible_targets:
        target_column = col
        break

if target_column is None:
    print("Could not find the target column automatically.")
    print("Columns in the dataset:", list(data.columns))
    target_column = input("Enter the correct target column name: ").strip()

print("Using target column:", target_column)

# 3. Split features and labels
X = data.drop(columns=[target_column])
y = data[target_column]

# Convert categorical data to numeric if needed
X = pd.get_dummies(X, drop_first=True)

# 4. Split into train and test data
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)
print("Data split done.")

# 5. Scale the features
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)
print("Data scaling complete.")

# 6. Train Random Forest model
rf_model = RandomForestClassifier(n_estimators=150, random_state=42)
rf_model.fit(X_train, y_train)
rf_pred = rf_model.predict(X_test)

print("\nRandom Forest Results:")
print(classification_report(y_test, rf_pred))

# 7. Build and train a simple ANN model
ann = models.Sequential([
    layers.Input(shape=(X_train.shape[1],)),
    layers.Dense(64, activation='relu'),
    layers.Dropout(0.2),
    layers.Dense(32, activation='relu'),
    layers.Dense(1, activation='sigmoid')
])

ann.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
print("\nTraining ANN model...")
history = ann.fit(X_train, y_train, epochs=30, batch_size=32, validation_split=0.1, verbose=2)

# 8. Test the ANN model
ann_probs = ann.predict(X_test).ravel()
ann_preds = (ann_probs > 0.5).astype(int)

print("\nANN Results:")
print(classification_report(y_test, ann_preds))
print("ROC-AUC Score:", roc_auc_score(y_test, ann_probs))

# 9. Save both models and the scaler
os.makedirs('output_models', exist_ok=True)
joblib.dump(rf_model, 'output_models/rf_model.joblib')
joblib.dump(scaler, 'output_models/scaler.joblib')
ann.save('output_models/ann_model.h5')

print("\nModels and scaler saved in 'output_models' folder.")

# 10. Plot ANN accuracy
plt.plot(history.history['accuracy'], label='train')
plt.plot(history.history['val_accuracy'], label='validation')
plt.title('Model Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()
plt.show()

print("Done.")
